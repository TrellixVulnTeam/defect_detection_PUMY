SCHEDULE:
  OPTIMIZER:
    type: "AdamW"
    lr: 0.0001
    betas: [0.9, 0.999]
    weight_decay: 0.0005
    PARAMWISE_CFG:
      custom_keys: [{}]
  OPTIMIZER_CONFIG:
    grad_clip: ""
    fp16: True
  LR_POLICY:
    policy: "CosineRestart"
    by_epoch: True
    periods: [60, 80]
    restart_weights: [1.0, 1.0]
    min_lr_ratio: 0.001
    warmup: "linear"
    warmup_iters: 1000
    warmup_ratio: 0.001
    warmup_by_epoch: False
  RUNNER:
    type: "EpochBasedRunner"
    max_epochs: 100
