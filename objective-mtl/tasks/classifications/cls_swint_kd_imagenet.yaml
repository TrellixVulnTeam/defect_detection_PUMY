MODEL:
  BASE: "models/classifications/cls_swint_fc_kd.yaml"
  PRETRAINED_MODEL_PATH: "meta/pretrained/swin_tiny_patch4_window7_224.pth"
  EXTEND_MODEL_PATH: "meta/pretrained/swin_large_dino_ep10_washed.pth"
DATA:
  BASE: "datasets/classifications/cls_imagenet_randaug.yaml"
  TRAIN_DATA:
    TYPE: "Concat" # "Concat" "Repeat" "Balanced"
    DATA_INFO: [['tfrecords/train*.tfrecord']] # "annotations/train.txt"
    SAMPLES_PER_DEVICE: 8
    WORKERS_PER_DEVICE: 8
  VAL_DATA:
    TYPE: "Normal"
    DATA_INFO: [['tfrecords/val*.tfrecord']] # "split_valid_tfrecord_0.0-944.20210505150928"
    SAMPLES_PER_DEVICE: 8
    WORKERS_PER_DEVICE: 8
  TEST_DATA:
    TYPE: "Normal"
    DATA_INFO: [['tfrecords/val*.tfrecord']] # "annotations/val.txt"
    SAMPLES_PER_DEVICE: 8
    WORKERS_PER_DEVICE: 8
SCHEDULE:
  BASE: "schedulers/schedule_adamw_ctm.yaml"
  OPTIMIZER:
    type: "AdamW"
    lr: 0.004
    betas: [0.9, 0.999]
    weight_decay: 0.05
    PARAMWISE_CFG:
      custom_keys: [{
        ".rpb": {decay_mult: 0},
        ".scale": {decay_mult: 0}
      }]
  OPTIMIZER_CONFIG:
    grad_clip: {max_norm: 5}
    fp16: False
  LR_POLICY:
    policy: "CosineAnnealing"
    by_epoch: False
    min_lr_ratio: 0.01
    warmup: "linear"
    warmup_iters: 80
    warmup_ratio: 0.001
    warmup_by_epoch: True
  RUNNER:
    type: "EpochBasedRunner"
    max_epochs: 100
RUNTIME:
  BASE: "runtimes/runtime_eval.yaml"
  WORKFLOW: [['train', 1]]
